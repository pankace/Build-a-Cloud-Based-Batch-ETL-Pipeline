name: Deploy ETL Pipeline

on:
  push:
    branches:
      - main
  workflow_dispatch:  # Allows manual triggering

env:
  TF_LOG: INFO
  GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp-credentials.json

jobs:
  build-and-deploy:
    name: Build and Deploy
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up GCP credentials
        run: |
          echo '${{ secrets.GCP_SA_KEY }}' > ${{ github.workspace }}/gcp-credentials.json

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          install_components: 'gke-gcloud-auth-plugin'

      - name: Configure Docker for GCR
        run: |
          gcloud auth configure-docker gcr.io --quiet

      # Build and push Extract component - FIXED COMMAND
      - name: Build Extract Docker image
        run: |
          cd ${{ github.workspace }}
          # Create a temporary cloudbuild.yaml for extract
          cat > cloudbuild-extract.yaml << EOF
          steps:
          - name: 'gcr.io/cloud-builders/docker'
            args: ['build', '-f', 'docker/extract/Dockerfile', '-t', 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:latest', '-t', 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:${{ github.sha }}', '.']
          images:
          - 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:latest'
          - 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:${{ github.sha }}'
          EOF
          
          # Submit the build
          gcloud builds submit --config cloudbuild-extract.yaml .
          echo "EXTRACT_IMAGE=gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:${{ github.sha }}" >> $GITHUB_ENV

      # Build and push Load component - FIXED COMMAND
      - name: Build Load Docker image
        run: |
          cd ${{ github.workspace }}
          # Create a temporary cloudbuild.yaml for load
          cat > cloudbuild-load.yaml << EOF
          steps:
          - name: 'gcr.io/cloud-builders/docker'
            args: ['build', '-f', 'docker/load/Dockerfile', '-t', 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:latest', '-t', 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:${{ github.sha }}', '.']
          images:
          - 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:latest'
          - 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:${{ github.sha }}'
          EOF
          
          # Submit the build
          gcloud builds submit --config cloudbuild-load.yaml .
          echo "LOAD_IMAGE=gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:${{ github.sha }}" >> $GITHUB_ENV

      # Setup Terraform
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.4.0
          terraform_wrapper: false

      # Create Terraform variables file
      - name: Create Terraform variable files
        run: |
          cd ${{ github.workspace }}/terraform
          
          cat > terraform.tfvars << EOF
          project_id = "${{ secrets.GCP_PROJECT_ID }}"
          project_number = "${{ secrets.GCP_PROJECT_NUMBER }}"
          extract_image = "${{ env.EXTRACT_IMAGE }}"
          load_image = "${{ env.LOAD_IMAGE }}"
          region = "${{ secrets.GCP_REGION || 'us-central1' }}"
          bucket_name = "${{ secrets.GCS_BUCKET_NAME || 'etl-data-bucket-${{ secrets.GCP_PROJECT_ID }}' }}"
          dataset_id = "${{ secrets.BIGQUERY_DATASET_ID || 'etl_dataset' }}"
          table_id = "${{ secrets.BIGQUERY_TABLE_ID || 'posts' }}"
          EOF
          
          cat terraform.tfvars

      # Initialize Terraform
      - name: Terraform Init
        working-directory: ${{ github.workspace }}/terraform
        run: |
          terraform init

      # Validate Terraform
      - name: Terraform Validate
        working-directory: ${{ github.workspace }}/terraform
        run: |
          terraform validate
          
      # Plan Terraform changes
      - name: Terraform Plan
        working-directory: ${{ github.workspace }}/terraform
        run: |
          terraform plan -out=tfplan

      # Apply Terraform changes
      - name: Terraform Apply
        working-directory: ${{ github.workspace }}/terraform
        run: |
          terraform apply -auto-approve tfplan

      # Test the deployment
      - name: Test Extract Function
        run: |
          # Wait for services to be fully deployed
          sleep 30
          
          # Get the extract function URL
          EXTRACT_URL=$(gcloud run services describe etl-extract-service \
            --region=${{ secrets.GCP_REGION || 'us-central1' }} \
            --format='value(status.url)')
          
          # Test the extract function
          curl -X POST $EXTRACT_URL \
            -H "Authorization: Bearer $(gcloud auth print-identity-token)" \
            -H "Content-Type: application/json" \
            -d '{}' \
            -o extract_response.json
          
          cat extract_response.json
          
          # Check if the response contains success: true
          if grep -q '"success":true' extract_response.json; then
            echo "✅ Extract function test passed"
          else
            echo "❌ Extract function test failed"
            exit 1
          fi

      # Cleanup
      - name: Cleanup
        if: always()
        run: |
          rm -f ${{ github.workspace }}/gcp-credentials.json