name: Deploy ETL Pipeline

on:
  push:
    branches:
      - main
  workflow_dispatch:  # Allows manual triggering

jobs:
  build-and-deploy:
    name: Build and Deploy
    runs-on: ubuntu-latest

    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      # Authenticate to Google Cloud using the official auth action
      - id: auth
        name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          create_credentials_file: true
          export_environment_variables: true
          
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          install_components: 'gke-gcloud-auth-plugin'

      # Configure Docker for GCR is handled by auth action

      # Build and push Extract component
      - name: Build Extract Docker image
        run: |
          cd ${{ github.workspace }}
          # Create a temporary cloudbuild.yaml for extract
          cat > cloudbuild-extract.yaml << EOF
          steps:
          - name: 'gcr.io/cloud-builders/docker'
            args: ['build', '-f', 'docker/extract/Dockerfile', '-t', 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:latest', '-t', 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:${{ github.sha }}', '.']
          images:
          - 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:latest'
          - 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:${{ github.sha }}'
          EOF
          
          # Submit the build
          gcloud builds submit --config cloudbuild-extract.yaml .
          echo "EXTRACT_IMAGE=gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-extract:${{ github.sha }}" >> $GITHUB_ENV

      # Build and push Load component
      - name: Build Load Docker image
        run: |
          cd ${{ github.workspace }}
          # Create a temporary cloudbuild.yaml for load
          cat > cloudbuild-load.yaml << EOF
          steps:
          - name: 'gcr.io/cloud-builders/docker'
            args: ['build', '-f', 'docker/load/Dockerfile', '-t', 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:latest', '-t', 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:${{ github.sha }}', '.']
          images:
          - 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:latest'
          - 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:${{ github.sha }}'
          EOF
          
          # Submit the build
          gcloud builds submit --config cloudbuild-load.yaml .
          echo "LOAD_IMAGE=gcr.io/${{ secrets.GCP_PROJECT_ID }}/etl-load:${{ github.sha }}" >> $GITHUB_ENV

      # Setup Terraform
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.4.0
          terraform_wrapper: false

      # Create Terraform variables file - FIXED VERSION
      - name: Create Terraform variable files
        run: |
          cd ${{ github.workspace }}/terraform
          
          # Create a bucket name variable first
          BUCKET_NAME="${{ secrets.GCS_BUCKET_NAME }}"
          if [ -z "$BUCKET_NAME" ]; then
            BUCKET_NAME="etl-data-bucket-${{ secrets.GCP_PROJECT_ID }}"
          fi
          
          # Now create the tfvars file using the variable
          cat > terraform.tfvars << EOF
          project_id = "${{ secrets.GCP_PROJECT_ID }}"
          project_number = "${{ secrets.GCP_PROJECT_NUMBER }}"
          extract_image = "${{ env.EXTRACT_IMAGE }}"
          load_image = "${{ env.LOAD_IMAGE }}"
          region = "${{ secrets.GCP_REGION || 'us-central1' }}"
          bucket_name = "$BUCKET_NAME"
          dataset_id = "${{ secrets.BIGQUERY_DATASET_ID || 'etl_dataset' }}"
          table_id = "${{ secrets.BIGQUERY_TABLE_ID || 'posts' }}"
          EOF
          
          cat terraform.tfvars

      # Initialize Terraform
      - name: Terraform Init
        working-directory: ${{ github.workspace }}/terraform
        run: |
          terraform init

      # Validate Terraform
      - name: Terraform Validate
        working-directory: ${{ github.workspace }}/terraform
        run: |
          terraform validate
          
      # Plan Terraform changes
      - name: Terraform Plan
        working-directory: ${{ github.workspace }}/terraform
        run: |
          terraform plan -out=tfplan

      # Apply Terraform changes
      - name: Terraform Apply
        working-directory: ${{ github.workspace }}/terraform
        run: |
          terraform apply -auto-approve tfplan

      # Test the deployment
      - name: Test Extract Function
        run: |
          # Wait for services to be fully deployed
          sleep 30
          
          # Get the extract function URL
          EXTRACT_URL=$(gcloud run services describe etl-extract-service \
            --region=${{ secrets.GCP_REGION || 'us-central1' }} \
            --format='value(status.url)')
          
          # Test the extract function
          curl -X POST $EXTRACT_URL \
            -H "Authorization: Bearer $(gcloud auth print-identity-token)" \
            -H "Content-Type: application/json" \
            -d '{}' \
            -o extract_response.json
          
          cat extract_response.json
          
          # Check if the response contains success: true
          if grep -q '"success":true' extract_response.json; then
            echo "✅ Extract function test passed"
          else
            echo "❌ Extract function test failed"
            exit 1
          fi